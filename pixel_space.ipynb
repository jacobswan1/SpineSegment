{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed images:1.Positive num:911.Total size:34848\n",
      "Processed images:2.Positive num:1854.Total size:69696\n",
      "Processed images:3.Positive num:2830.Total size:104544\n",
      "Processed images:4.Positive num:3771.Total size:139392\n",
      "Processed images:5.Positive num:4690.Total size:174240\n",
      "Processed images:6.Positive num:5540.Total size:209088\n",
      "Processed images:7.Positive num:5555.Total size:243936\n",
      "Processed images:8.Positive num:5567.Total size:278784\n",
      "Processed images:9.Positive num:5578.Total size:313632\n",
      "Processed images:10.Positive num:5873.Total size:348480\n",
      "Processed images:11.Positive num:6156.Total size:383328\n",
      "Processed images:12.Positive num:6386.Total size:418176\n",
      "Processed images:13.Positive num:6642.Total size:453024\n",
      "Processed images:14.Positive num:6942.Total size:487872\n",
      "Processed images:15.Positive num:7540.Total size:522720\n",
      "Processed images:16.Positive num:8055.Total size:557568\n",
      "Processed images:17.Positive num:8546.Total size:592416\n",
      "Processed images:18.Positive num:9023.Total size:627264\n",
      "Processed images:19.Positive num:9554.Total size:662112\n",
      "Processed images:20.Positive num:9562.Total size:696960\n",
      "Processed images:21.Positive num:9575.Total size:731808\n",
      "Processed images:22.Positive num:9588.Total size:766656\n"
     ]
    }
   ],
   "source": [
    "    import cv2\n",
    "    import numpy as np\n",
    "    import os\n",
    "    import dicom\n",
    "    import data\n",
    "    import copy\n",
    "    from keras.models import Sequential\n",
    "    from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "    from keras.layers import Convolution2D, MaxPooling2D\n",
    "    from keras.utils import np_utils\n",
    "    from keras.optimizers import SGD\n",
    "    from keras.utils import np_utils\n",
    "\n",
    "    RECEP_HEI = 56\n",
    "    RECEP_WEI = 28\n",
    "    DATA_PATH = os.getcwd()\n",
    "    MODE_TEST_PATH = '/data/metROI/test_txt'\n",
    "    \n",
    "    nb_classes = 2\n",
    "    count_img = 0\n",
    "    count = 0\n",
    "    index = 0\n",
    "    count_pos = 0\n",
    "    class_lable = 2\n",
    "    x_start = RECEP_WEI\n",
    "    y_start = RECEP_HEI\n",
    "\n",
    "    TRAIN_DATA_TXT_PATH = DATA_PATH + MODE_TEST_PATH\n",
    "    IMG_LIST = os.listdir(TRAIN_DATA_TXT_PATH)\n",
    "    TRAIN_NUM = len(IMG_LIST)\n",
    "    TRAIN_OUT = []\n",
    "    TRAIN_IN = []\n",
    "    Resolution = []\n",
    "    for name in IMG_LIST:\n",
    "        \n",
    "        med_img, test_array = get_input_and_output(TRAIN_DATA_TXT_PATH + '/' + name)\n",
    "        med_img_pix = cv2.resize(med_img.pixel_array, (320, 320), interpolation=cv2.INTER_AREA)\n",
    "        test_array = test_array + 0.001\n",
    "        test_array = cv2.resize(test_array, (320, 320), interpolation=cv2.INTER_AREA)\n",
    "        \n",
    "        \n",
    "        cropImg1 = med_img_pix[0:med_img.Rows, 320/ 4: 3 * 320 / 4]\n",
    "        cropImg2 = test_array[0:med_img.Rows, 320 / 4: 3 * 320 / 4]\n",
    "        \n",
    "        Resolution.append( med_img.PixelSpacing[0]* med_img.Rows / np.float(320) )\n",
    "        y_max = 320\n",
    "        x_max = 320 / 2\n",
    "        \n",
    "        for i in range(y_start, y_max):\n",
    "            for m in range(x_start, x_max):\n",
    "                region = cropImg1[i - RECEP_HEI: i, m - RECEP_WEI: m]\n",
    "                class_lable = cropImg2[i - RECEP_HEI / 2][m - RECEP_WEI / 2]\n",
    "                if(class_lable != 1.001 ):\n",
    "                    TRAIN_IN.append(region.reshape(1, RECEP_HEI, RECEP_WEI))\n",
    "                    TRAIN_OUT.append(np_utils.to_categorical([0], nb_classes)[0])\n",
    "                    index += 1\n",
    "                    # print(index)\n",
    "\n",
    "                elif (class_lable == 1.001):\n",
    "                    TRAIN_IN.append(region.reshape(1, RECEP_HEI, RECEP_WEI))\n",
    "                    TRAIN_OUT.append(np_utils.to_categorical([1], nb_classes)[0])\n",
    "                    count_pos += 1\n",
    "                    index += 1\n",
    "                    # print(index)\n",
    "\n",
    "                count += 1\n",
    "        if(index % 1000 == 0):\n",
    "                print('Processed training set:' + str(index))\n",
    "\n",
    "        count_img += 1\n",
    "        print('Processed images:' + str(count_img) + '.Positive num:' +\n",
    "              str(count_pos) + '.Total size:' + str(index))\n",
    "    TRAIN_IN = np.asarray(TRAIN_IN, dtype=np.float)\n",
    "    TRAIN_OUT = np.asarray(TRAIN_OUT, dtype=np.float)\n",
    "    Resolution = np.asarray(Resolution)\n",
    "\n",
    "#     print('Normalizing training data...')\n",
    "#     for i in range(TRAIN_IN.shape[0]):\n",
    "#         for m in range(TRAIN_IN.shape[1]):\n",
    "\n",
    "#             mean = np.mean(TRAIN_IN[i][m])  # mean for data centering\n",
    "#             std = np.std(TRAIN_IN[i][m])  # std for data normalization\n",
    "#             TRAIN_IN[i][m] = (TRAIN_IN[i][m] - mean) / std\n",
    "#     model = getmodel()\n",
    "#     print('Predicting...')\n",
    "#     predict_result = model.predict_classes(TRAIN_IN)\n",
    "#     np.save('answer_image'+'.npy',TRAIN_OUT)\n",
    "#     np.save('predicted_image'+'.npy', predict_result)\n",
    "#     np.save('input_image'+'.npy',TRAIN_IN)\n",
    "#     np.save('resolution'+'.npy', Resolution)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_input_and_output(source):\n",
    "    file = open(source, 'r')\n",
    "    list = file.readlines()\n",
    "    test_array = np.empty((0, len(list)), int)\n",
    "    for line in list:\n",
    "        # print line\n",
    "        line = line.split(',')\n",
    "        line[len(line) - 1] = line[len(line) - 1].replace('\\n', '')\n",
    "        line = map(int, line)\n",
    "        test_array = np.append(test_array, np.array([line]), axis=0)\n",
    "    dir_array = source.split('/')\n",
    "    dir_name = dir_array[len(dir_array) - 1].split('_')\n",
    "    dir_image_file = DATA_PATH + '/data/Sagittal-segmentation/' + \\\n",
    "        dir_name[0] + '/' + dir_name[1] + '/' + \\\n",
    "            str(dir_name[2]).replace('txt', 'dcm')\n",
    "    medical_img = dicom.read_file(dir_image_file)\n",
    "    return medical_img, test_array\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2319040, 1, 56, 28)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TRAIN_IN.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       ..., \n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TRAIN_OUT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  5.12000000e+02,   3.84000000e+02,   5.85900000e-01,\n",
       "          5.85900000e-01],\n",
       "       [  5.12000000e+02,   3.84000000e+02,   5.85900000e-01,\n",
       "          5.85900000e-01],\n",
       "       [  5.12000000e+02,   3.84000000e+02,   5.85900000e-01,\n",
       "          5.85900000e-01],\n",
       "       [  5.12000000e+02,   3.84000000e+02,   5.85900000e-01,\n",
       "          5.85900000e-01],\n",
       "       [  5.12000000e+02,   3.84000000e+02,   5.85900000e-01,\n",
       "          5.85900000e-01],\n",
       "       [  5.12000000e+02,   3.84000000e+02,   5.85900000e-01,\n",
       "          5.85900000e-01],\n",
       "       [  3.84000000e+02,   2.88000000e+02,   7.29166687e-01,\n",
       "          7.29166687e-01],\n",
       "       [  3.84000000e+02,   2.88000000e+02,   7.29166687e-01,\n",
       "          7.29166687e-01],\n",
       "       [  3.84000000e+02,   2.88000000e+02,   7.29166687e-01,\n",
       "          7.29166687e-01],\n",
       "       [  5.12000000e+02,   3.84000000e+02,   5.46900000e-01,\n",
       "          5.46900000e-01],\n",
       "       [  5.12000000e+02,   3.84000000e+02,   5.46900000e-01,\n",
       "          5.46900000e-01],\n",
       "       [  5.12000000e+02,   3.84000000e+02,   5.46900000e-01,\n",
       "          5.46900000e-01],\n",
       "       [  5.12000000e+02,   3.84000000e+02,   5.46900000e-01,\n",
       "          5.46900000e-01],\n",
       "       [  5.12000000e+02,   3.84000000e+02,   5.46900000e-01,\n",
       "          5.46900000e-01],\n",
       "       [  6.40000000e+02,   4.80000000e+02,   5.62500000e-01,\n",
       "          5.62500000e-01],\n",
       "       [  6.40000000e+02,   4.80000000e+02,   5.62500000e-01,\n",
       "          5.62500000e-01],\n",
       "       [  6.40000000e+02,   4.80000000e+02,   5.62500000e-01,\n",
       "          5.62500000e-01],\n",
       "       [  6.40000000e+02,   4.80000000e+02,   5.62500000e-01,\n",
       "          5.62500000e-01],\n",
       "       [  6.40000000e+02,   4.80000000e+02,   5.62500000e-01,\n",
       "          5.62500000e-01],\n",
       "       [  3.84000000e+02,   2.88000000e+02,   7.29166687e-01,\n",
       "          7.29166687e-01],\n",
       "       [  3.84000000e+02,   2.88000000e+02,   7.29166687e-01,\n",
       "          7.29166687e-01],\n",
       "       [  3.84000000e+02,   2.88000000e+02,   7.29166687e-01,\n",
       "          7.29166687e-01]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Resolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0008, 0008) Image Type                          CS: ['ORIGINAL', 'PRIMARY', 'M', 'NORM', 'DIS2D', 'FM', 'FIL']\n",
       "(0008, 0012) Instance Creation Date              DA: '20090521'\n",
       "(0008, 0013) Instance Creation Time              TM: '130551.859000'\n",
       "(0008, 0016) SOP Class UID                       UI: MR Image Storage\n",
       "(0008, 0018) SOP Instance UID                    UI: 1.3.6.1.4.1.9590.100.1.2.141582010413708326808827334470320252517\n",
       "(0008, 0020) Study Date                          DA: '20090521'\n",
       "(0008, 0021) Series Date                         DA: '20090521'\n",
       "(0008, 0022) Acquisition Date                    DA: '20090521'\n",
       "(0008, 0023) Content Date                        DA: '20090521'\n",
       "(0008, 0030) Study Time                          TM: '125806.375000'\n",
       "(0008, 0031) Series Time                         TM: '130548.609000'\n",
       "(0008, 0032) Acquisition Time                    TM: '130446.967500'\n",
       "(0008, 0033) Content Time                        TM: '130551.859000'\n",
       "(0008, 0050) Accession Number                    SH: 'ZH090521MR2009'\n",
       "(0008, 0060) Modality                            CS: 'MR'\n",
       "(0008, 0070) Manufacturer                        LO: 'SIEMENS'\n",
       "(0008, 0080) Institution Name                    LO: ''\n",
       "(0008, 0081) Institution Address                 ST: ''\n",
       "(0008, 0090) Referring Physician's Name          PN: ''\n",
       "(0008, 1010) Station Name                        SH: 'MRC35183'\n",
       "(0008, 1030) Study Description                   LO: 'c-spine^general'\n",
       "(0008, 103e) Series Description                  LO: 't2_tse_rst_sag_TI 200ms_FIL'\n",
       "(0008, 1050) Performing Physician's Name         PN: '1279994'\n",
       "(0008, 1090) Manufacturer's Model Name           LO: 'TrioTim'\n",
       "(0010, 0010) Patient's Name                      PN: ''\n",
       "(0010, 0020) Patient ID                          LO: '841319'\n",
       "(0010, 0030) Patient's Birth Date                DA: '19760610'\n",
       "(0010, 0040) Patient's Sex                       CS: 'M'\n",
       "(0010, 1010) Patient's Age                       AS: '032Y'\n",
       "(0010, 1030) Patient's Weight                    DS: '90'\n",
       "(0018, 0020) Scanning Sequence                   CS: ['SE', 'IR']\n",
       "(0018, 0021) Sequence Variant                    CS: ['SK', 'SP', 'MP', 'OSP']\n",
       "(0018, 0022) Scan Options                        CS: 'IR'\n",
       "(0018, 0023) MR Acquisition Type                 CS: '2D'\n",
       "(0018, 0024) Sequence Name                       SH: '*tirR2d1rr29'\n",
       "(0018, 0025) Angio Flag                          CS: 'N'\n",
       "(0018, 0050) Slice Thickness                     DS: '3'\n",
       "(0018, 0080) Repetition Time                     DS: '3440'\n",
       "(0018, 0081) Echo Time                           DS: '102'\n",
       "(0018, 0083) Number of Averages                  DS: '2'\n",
       "(0018, 0084) Imaging Frequency                   DS: '123.253381'\n",
       "(0018, 0085) Imaged Nucleus                      SH: '1H'\n",
       "(0018, 0086) Echo Number(s)                      IS: '1'\n",
       "(0018, 0087) Magnetic Field Strength             DS: '3'\n",
       "(0018, 0088) Spacing Between Slices              DS: '3.3'\n",
       "(0018, 0089) Number of Phase Encoding Steps      IS: '523'\n",
       "(0018, 0091) Echo Train Length                   IS: '29'\n",
       "(0018, 0093) Percent Sampling                    DS: '67.9688'\n",
       "(0018, 0094) Percent Phase Field of View         DS: '100'\n",
       "(0018, 0095) Pixel Bandwidth                     DS: '320'\n",
       "(0018, 1000) Device Serial Number                LO: '35183'\n",
       "(0018, 1020) Software Version(s)                 LO: 'syngo MR B15'\n",
       "(0018, 1030) Protocol Name                       LO: 't2_tse_rst_sag_TI 200ms'\n",
       "(0018, 1251) Transmit Coil Name                  SH: 'Body'\n",
       "(0018, 1310) Acquisition Matrix                  US: [384, 0, 0, 261]\n",
       "(0018, 1312) In-plane Phase Encoding Direction   CS: 'COL'\n",
       "(0018, 1314) Flip Angle                          DS: '180'\n",
       "(0018, 1315) Variable Flip Angle Flag            CS: 'N'\n",
       "(0018, 1316) SAR                                 DS: '0.83792859920917'\n",
       "(0018, 1318) dB/dt                               DS: '0'\n",
       "(0018, 5100) Patient Position                    CS: 'HFS'\n",
       "(0020, 000d) Study Instance UID                  UI: 1279994\n",
       "(0020, 000e) Series Instance UID                 UI: 1.3.12.2.1107.5.2.32.35183.2009052113054843184978196.0.0.0\n",
       "(0020, 0010) Study ID                            SH: '773'\n",
       "(0020, 0011) Series Number                       IS: '4'\n",
       "(0020, 0012) Acquisition Number                  IS: '1'\n",
       "(0020, 0013) Instance Number                     IS: '10'\n",
       "(0020, 0032) Image Position (Patient)            DS: ['-0.0632834401209', '-157.58043515263', '101.4409126895']\n",
       "(0020, 0037) Image Orientation (Patient)         DS: ['0.0027114887006', '0.9848147530153', '0.173587298131', '0.0273617751231', '0.1734498787843', '-0.9844625299176']\n",
       "(0020, 0052) Frame of Reference UID              UI: 1.3.12.2.1107.5.2.32.35183.2.20090521125806609.0.0.0\n",
       "(0020, 1040) Position Reference Indicator        LO: ''\n",
       "(0020, 1041) Slice Location                      DS: '3.7915790063528'\n",
       "(0028, 0002) Samples per Pixel                   US: 1\n",
       "(0028, 0004) Photometric Interpretation          CS: 'MONOCHROME2'\n",
       "(0028, 0010) Rows                                US: 384\n",
       "(0028, 0011) Columns                             US: 384\n",
       "(0028, 0030) Pixel Spacing                       DS: ['0.72916668653488', '0.72916668653488']\n",
       "(0028, 0100) Bits Allocated                      US: 16\n",
       "(0028, 0101) Bits Stored                         US: 16\n",
       "(0028, 0102) High Bit                            US: 15\n",
       "(0028, 0103) Pixel Representation                US: 0\n",
       "(0028, 0106) Smallest Image Pixel Value          US: 0\n",
       "(0028, 0107) Largest Image Pixel Value           US: 1247\n",
       "(0028, 1050) Window Center                       DS: '266'\n",
       "(0028, 1051) Window Width                        DS: '661'\n",
       "(0040, 0244) Performed Procedure Step Start Date DA: '20090521'\n",
       "(0040, 0245) Performed Procedure Step Start Time TM: '125806.500000'\n",
       "(0040, 0253) Performed Procedure Step ID         SH: '4652'\n",
       "(0040, 0254) Performed Procedure Step Descriptio LO: 'MR C-spine PS+CE'\n",
       "(7fe0, 0010) Pixel Data                          OW: Array of 294912 bytes"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "med_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.001,  0.001,  0.001, ...,  0.001,  0.001,  0.001],\n",
       "       [ 0.001,  0.001,  0.001, ...,  0.001,  0.001,  0.001],\n",
       "       [ 0.001,  0.001,  0.001, ...,  0.001,  0.001,  0.001],\n",
       "       ..., \n",
       "       [ 0.001,  0.001,  0.001, ...,  0.001,  0.001,  0.001],\n",
       "       [ 0.001,  0.001,  0.001, ...,  0.001,  0.001,  0.001],\n",
       "       [ 0.001,  0.001,  0.001, ...,  0.001,  0.001,  0.001]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cropImg2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(766656, 2)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TRAIN_OUT.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import dicom\n",
    "import data\n",
    "import copy\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Convolution2D, MaxPooling2D\n",
    "from keras.utils import np_utils\n",
    "from scipy import ndimage\n",
    "from keras.optimizers import SGD\n",
    "from keras.utils import np_utils\n",
    "from skimage.morphology import remove_small_objects\n",
    "from scipy import ndimage\n",
    "from sklearn import metrics, metrics\n",
    "from scipy.ndimage.measurements import label\n",
    "\n",
    "\n",
    "def getPara(predict, true, threshold, resolution):\n",
    "    (TP, FP, TN, FN, class_lable) = perf_measure(true, predict, threshold)\n",
    "    if((TP + FN) == 0):\n",
    "        TPR = 0\n",
    "    else:\n",
    "        TPR = np.float(TP) / (TP + FN)\n",
    "\n",
    "    class_lable = class_lable.astype(\n",
    "        bool).reshape(320 ,  160)\n",
    "    true = true.astype(bool).reshape(320 , 160)\n",
    "\n",
    "    predict2 = remove_small_objects(class_lable, 160 * resolution, in_place=False)\n",
    "    labeled_array1, num_features1 = label(predict2)\n",
    "    labeled_array2, num_features2 = label(true)\n",
    "    FP_num = num_features1 - num_features2\n",
    "    if FP_num < 0:\n",
    "        FP_num = 0\n",
    "    return TPR, FP_num\n",
    "\n",
    "\n",
    "def perf_measure(y_actual, predict, threshold):\n",
    "    TP = 0\n",
    "    FP = 0\n",
    "    TN = 0\n",
    "    FN = 0\n",
    "    predict = transfer_prob(predict, threshold)\n",
    "    for i in range(len(predict)):\n",
    "        if y_actual[i] == predict[i] == 1:\n",
    "            TP += 1\n",
    "    for i in range(len(predict)):\n",
    "        if y_actual[i] == 0 and y_actual[i] != predict[i]:\n",
    "            FP += 1\n",
    "    for i in range(len(predict)):\n",
    "        if y_actual[i] == predict[i] == 0:\n",
    "            TN += 1\n",
    "    for i in range(len(predict)):\n",
    "        if y_actual[i] == 1 and y_actual[i] != predict[i]:\n",
    "            FN += 1\n",
    "\n",
    "    return(TP, FP, TN, FN, predict)\n",
    "\n",
    "\n",
    "def transfer_prob(y_score, threshold):\n",
    "    y_result = []\n",
    "    for i in range(len(y_score)):\n",
    "        if y_score[i] >= threshold:\n",
    "            y_result.append(1)\n",
    "        else:\n",
    "            y_result.append(0)\n",
    "    return np.asarray(y_result)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_score = np.load('./resolution/predicted_image.npy')\n",
    "y_true = np.load('./resolution/answer_image.npy')\n",
    "reso = np.load('./resolution/resolution.npy')\n",
    "\n",
    "y_score = y_score[0:y_score.shape[0], 1]\n",
    "y_true = y_true[0:y_true.shape[0], 1]\n",
    "\n",
    "scores = []\n",
    "trues = []\n",
    "next_start = 0\n",
    "for i in range(len(reso)):\n",
    "    ysize = 264\n",
    "    xsize = 132\n",
    "    scores.append(y_score[next_start: next_start + np.int(ysize * xsize)])\n",
    "    trues.append(y_true[next_start: next_start + np.int(ysize * xsize)])\n",
    "    next_start = np.int(next_start + ysize * xsize)\n",
    "\n",
    "\n",
    "y_score = np.asarray(scores)\n",
    "y_true = np.asarray(trues)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       ..., \n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.]])"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tmp2 = y_score[9].reshape(264, 132)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from scipy.ndimage.morphology import binary_erosion, binary_dilation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x11dbb9090>"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAJUAAAEACAYAAAC6fjQLAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nwJdttj63AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11db3e090>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tmp2 = tmp2>0.1\n",
    "\n",
    "num = 2\n",
    "x = np.arange( -num , num+1, 1)\n",
    "xx, yy  = np.meshgrid( x, x )\n",
    "struc = (xx * xx + yy * yy)<= num * num\n",
    "tmp2 = binary_dilation(tmp2, struc)\n",
    "tmp2 = binary_erosion(tmp2, struc)\n",
    "plt.imshow(tmp2>0.1,'gray')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[False, False,  True, False, False],\n",
       "       [False,  True,  True,  True, False],\n",
       "       [ True,  True,  True,  True,  True],\n",
       "       [False,  True,  True,  True, False],\n",
       "       [False, False,  True, False, False]], dtype=bool)"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "struc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x11bd739d0>"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAJUAAAEACAYAAAC6fjQLAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11bbe5b50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tmp = y_true[9].reshape(264, 132)\n",
    "plt.imshow(tmp,'gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "out = TRAIN_OUT[0:TRAIN_OUT.shape[0], 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "o = []\n",
    "next_start = 0\n",
    "ysize = 264\n",
    "xsize = 132\n",
    "for i in range((22)):\n",
    "    o.append(out[next_start: next_start + np.int(ysize * xsize)])\n",
    "    next_start = np.int(next_start + ysize * xsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed images:1.Positive num:911.Total size:34848\n",
      "Processed images:2.Positive num:1854.Total size:69696\n",
      "Processed images:3.Positive num:2830.Total size:104544\n",
      "Processed images:4.Positive num:3771.Total size:139392\n",
      "Processed images:5.Positive num:4690.Total size:174240\n",
      "Processed images:6.Positive num:5540.Total size:209088\n",
      "Processed images:7.Positive num:5555.Total size:243936\n",
      "Processed images:8.Positive num:5567.Total size:278784\n",
      "Processed images:9.Positive num:5578.Total size:313632\n",
      "Processed images:10.Positive num:5873.Total size:348480\n",
      "Processed images:11.Positive num:6156.Total size:383328\n",
      "Processed images:12.Positive num:6386.Total size:418176\n",
      "Processed images:13.Positive num:6642.Total size:453024\n",
      "Processed images:14.Positive num:6942.Total size:487872\n",
      "Processed images:15.Positive num:7540.Total size:522720\n",
      "Processed images:16.Positive num:8055.Total size:557568\n",
      "Processed images:17.Positive num:8546.Total size:592416\n",
      "Processed images:18.Positive num:9023.Total size:627264\n",
      "Processed images:19.Positive num:9554.Total size:662112\n",
      "Processed images:20.Positive num:9562.Total size:696960\n",
      "Processed images:21.Positive num:9575.Total size:731808\n",
      "Processed images:22.Positive num:9588.Total size:766656\n"
     ]
    }
   ],
   "source": [
    "    count_img = 0\n",
    "    count = 0\n",
    "    index = 0\n",
    "    count_pos = 0\n",
    "    class_lable = 2\n",
    "    x_start = RECEP_WEI\n",
    "    y_start = RECEP_HEI\n",
    "\n",
    "    TRAIN_DATA_TXT_PATH = DATA_PATH + MODE_TEST_PATH\n",
    "    IMG_LIST = os.listdir(TRAIN_DATA_TXT_PATH)\n",
    "    TRAIN_NUM = len(IMG_LIST)\n",
    "    TRAIN_OUT = []\n",
    "    TRAIN_IN = []\n",
    "    Resolution = []\n",
    "    for name in IMG_LIST:\n",
    "\n",
    "        med_img, test_array = get_input_and_output(TRAIN_DATA_TXT_PATH + '/' + name)\n",
    "        med_img_pix = cv2.resize(med_img.pixel_array, (320, 320), interpolation=cv2.INTER_AREA)\n",
    "        test_array = test_array + 0.001\n",
    "        test_array = cv2.resize(test_array, (320, 320), interpolation=cv2.INTER_AREA)\n",
    "\n",
    "\n",
    "        cropImg1 = med_img_pix[0:320, 320/ 4: 3 * 320 / 4]\n",
    "        cropImg2 = test_array[0:320, 320 / 4: 3 * 320 / 4]\n",
    "\n",
    "        Resolution.append( med_img.PixelSpacing[0]* med_img.Rows / np.float(320) )\n",
    "        y_max = 320\n",
    "        x_max = 320 / 2\n",
    "\n",
    "        for i in range(y_start, y_max):\n",
    "            for m in range(x_start, x_max):\n",
    "                region = cropImg1[i - RECEP_HEI: i, m - RECEP_WEI: m]\n",
    "                class_lable = cropImg2[i - RECEP_HEI / 2][m - RECEP_WEI / 2]\n",
    "                if(class_lable != 1.001 ):\n",
    "                    TRAIN_IN.append(region.reshape(1, RECEP_HEI, RECEP_WEI))\n",
    "                    TRAIN_OUT.append(np_utils.to_categorical([0], nb_classes)[0])\n",
    "                    index += 1\n",
    "                    # print(index)\n",
    "\n",
    "                elif (class_lable == 1.001):\n",
    "                    TRAIN_IN.append(region.reshape(1, RECEP_HEI, RECEP_WEI))\n",
    "                    TRAIN_OUT.append(np_utils.to_categorical([1], nb_classes)[0])\n",
    "                    count_pos += 1\n",
    "                    index += 1\n",
    "                    # print(index)\n",
    "\n",
    "                count += 1\n",
    "        if(index % 1000 == 0):\n",
    "                print('Processed training set:' + str(index))\n",
    "\n",
    "        count_img += 1\n",
    "        print('Processed images:' + str(count_img) + '.Positive num:' +\n",
    "              str(count_pos) + '.Total size:' + str(index))\n",
    "    TRAIN_IN = np.asarray(TRAIN_IN, dtype=np.float)\n",
    "    TRAIN_OUT = np.asarray(TRAIN_OUT, dtype=np.float)\n",
    "    Resolution = np.asarray(Resolution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "TRAIN_OUT = TRAIN_OUT[0:TRAIN_OUT.shape[0], 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tmp = TRAIN_OUT[0:34848]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
